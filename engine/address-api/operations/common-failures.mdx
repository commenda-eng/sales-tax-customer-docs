---
title: Common failures
description: Common failure scenarios and how to fix them
---

This guide covers common failure scenarios for the Address API and how to resolve them.

## Failed migration

### Symptoms

- Deployment fails during migration step
- ECS tasks fail to start
- CloudWatch logs show migration errors

### Common causes

#### 1. Duplicate records violating unique constraint

**Scenario**: Adding a unique constraint to a table that has duplicate records.

**Example error**:
```
ERROR: could not create unique index "iso_3166_country_subdivision_unique"
DETAIL: Key (country_code, subdivision_code)=(US, CA) is duplicated.
```

**Fix**:

1. Connect to the database (see [Database connection](/engine/address-api/operations/database-connection))

2. Identify duplicates:
   ```sql
   SELECT country_code, subdivision_code, COUNT(*)
   FROM iso_3166
   GROUP BY country_code, subdivision_code
   HAVING COUNT(*) > 1;
   ```

3. Remove duplicates (keep the most recent):
   ```sql
   DELETE FROM iso_3166 a
   USING iso_3166 b
   WHERE a.id < b.id
     AND a.country_code = b.country_code
     AND a.subdivision_code = b.subdivision_code;
   ```

4. Update the Atlas migration table to mark the migration as applied:
   ```sql
   -- Check current migration status
   SELECT * FROM atlas_schema_revisions ORDER BY executed_at DESC;
   
   -- If the migration is marked as failed, you may need to manually mark it as applied
   -- after fixing the data issue and re-running the migration
   ```

5. Re-run the migration:
   ```bash
   atlas migrate apply \
     --dir "file://database/migrations" \
     --url "postgresql://USERNAME:PASSWORD@HOSTNAME:PORT/DBNAME"
   ```

6. Redeploy the service:
   ```bash
   aws ecs update-service \
     --cluster staging-ecs-cluster \
     --service address-api \
     --force-new-deployment \
     --region ap-south-1
   ```

#### 2. Migration syntax error

**Scenario**: SQL syntax error in migration file.

**Fix**:

1. Review the migration file in `database/migrations/`
2. Fix the SQL syntax error
3. Commit and push the fix
4. Create a new release to redeploy

#### 3. Migration timeout

**Scenario**: Migration takes too long and times out.

**Fix**:

1. Increase the migration timeout in the deployment workflow
2. Optimize the migration (add indexes after data migration, not during)
3. Consider breaking large migrations into smaller steps

## Google API issues

### 1. Missing API key

**Symptoms**:
- Server fails to start
- CloudWatch logs show: \"GOOGLE_GEOCODING_API_KEY is required\"

**Fix**:

1. Check Secrets Manager:
   ```bash
   aws secretsmanager get-secret-value \
     --secret-id staging-address-api-secrets \
     --region ap-south-1
   ```

2. Add the missing key:
   ```bash
   aws secretsmanager update-secret \
     --secret-id staging-address-api-secrets \
     --secret-string '{\"GOOGLE_GEOCODING_API_KEY\":\"your-key-here\"}' \
     --region ap-south-1
   ```

3. Restart the ECS service:
   ```bash
   aws ecs update-service \
     --cluster staging-ecs-cluster \
     --service address-api \
     --force-new-deployment \
     --region ap-south-1
   ```

### 2. Invalid API key

**Symptoms**:
- Geocoding requests fail with 500 errors
- CloudWatch logs show: \"Google API authentication failed\"

**Fix**:

1. Verify the API key in Google Cloud Console
2. Ensure the Geocoding API is enabled
3. Check API key restrictions (IP, referrer, API)
4. Update the key in Secrets Manager
5. Restart the ECS service

### 3. Google API quota exceeded

**Symptoms**:
- Geocoding requests fail with \"OVER_QUERY_LIMIT\"
- Only cached addresses work

**Fix**:

**Short-term**:
- Requests for cached addresses will continue to work
- New addresses will fail until quota resets

**Long-term**:
1. Increase Google API quota in Google Cloud Console
2. Implement rate limiting
3. Optimize cache usage

### 4. Google API is down

**Symptoms**:
- Geocoding requests fail for non-cached addresses
- Cached addresses still work
- CloudWatch logs show: \"failed to connect to Google API\"

**Behavior**:
- **Cached addresses**: Continue to work normally
- **New addresses**: Return 500 error

**Fix**:

1. Check [Google Cloud Status Dashboard](https://status.cloud.google.com/)
2. Wait for Google to resolve the issue
3. Monitor Better Stack for alerts
4. Cached addresses will continue to work during the outage

## RDS (database) issues

### 1. Database is down

**Symptoms**:
- Health check endpoint returns 500 error
- Better Stack alerts: \"Service is down\"
- CloudWatch logs show: \"could not ping the database\"

**Fix**:

1. Check RDS instance status:
   ```bash
   aws rds describe-db-instances \
     --db-instance-identifier staging-address-api-postgres \
     --region ap-south-1
   ```

2. If stopped, start the instance:
   ```bash
   aws rds start-db-instance \
     --db-instance-identifier staging-address-api-postgres \
     --region ap-south-1
   ```

3. If the instance is in a failed state, check CloudWatch logs for RDS
4. Consider restoring from a snapshot if the instance is corrupted

### 2. Connection pool exhausted

**Symptoms**:
- Requests timeout or fail
- Health check shows `acquired_connections` near `max_connections`
- CloudWatch logs show: \"connection pool exhausted\"

**Fix**:

1. Check current pool usage:
   ```bash
   curl https://address.in.staging.commenda.io/healthz
   ```

2. Increase connection pool size:
   - Edit `configs/postgres.config.go`
   - Increase `MaxConns` (currently 48)
   - Deploy the change

3. Check for connection leaks:
   ```sql
   SELECT 
     datname,
     usename,
     application_name,
     state,
     COUNT(*)
   FROM pg_stat_activity
   WHERE datname = 'address_api'
   GROUP BY datname, usename, application_name, state;
   ```

4. Kill idle connections if needed:
   ```sql
   SELECT pg_terminate_backend(pid)
   FROM pg_stat_activity
   WHERE datname = 'address_api'
     AND state = 'idle'
     AND state_change < NOW() - INTERVAL '10 minutes';
   ```

### 3. Database credentials invalid

**Symptoms**:
- Server fails to start
- CloudWatch logs show: \"password authentication failed\"

**Fix**:

1. Verify credentials in Secrets Manager
2. Reset RDS password if needed:
   ```bash
   aws rds modify-db-instance \
     --db-instance-identifier staging-address-api-postgres \
     --master-user-password NEW_PASSWORD \
     --region ap-south-1
   ```

3. Update Secrets Manager with new password
4. Restart ECS service

### 4. Database disk full

**Symptoms**:
- Write operations fail
- CloudWatch logs show: \"disk full\" or \"no space left on device\"

**Fix**:

1. Check disk usage:
   ```bash
   aws rds describe-db-instances \
     --db-instance-identifier staging-address-api-postgres \
     --query 'DBInstances[0].AllocatedStorage' \
     --region ap-south-1
   ```

2. Increase storage:
   ```bash
   aws rds modify-db-instance \
     --db-instance-identifier staging-address-api-postgres \
     --allocated-storage 100 \
     --region ap-south-1
   ```

3. Clean up old data:
   ```sql
   -- Delete old cache entries
   DELETE FROM address_cache 
   WHERE cached_at < EXTRACT(EPOCH FROM NOW() - INTERVAL '90 days');
   
   -- Vacuum to reclaim space
   VACUUM FULL address_cache;
   ```

## ISO 3166 content issues

### Missing state code

**Symptoms**:
- Geocoding works but returns Google's short name instead of ISO code
- No error is thrown

**Behavior**:
When Google returns a state code that doesn't exist in the ISO 3166 database:
1. The API tries to match the code against `subdivision_code`
2. If not found, tries to match against `subdivision_name`
3. If not found, tries to match against `subdivision_local_variant`
4. If still not found, returns Google's short name without failing

**Example**:
```json
{
  \"state\": \"California\",
  \"state_code\": \"CA\"  // Google's short name, not from ISO 3166 database
}
```

**Fix**:

1. Ingest the missing state code:
   ```bash
   curl -X POST https://address.in.commenda.io/api/v1/internal/iso_3166/ingest/json \
     -H \"x-commenda-key: your-api-key\" \
     -H \"Content-Type: application/json\" \
     -d '{
       \"items\": [{
         \"country_code\": \"US\",
         \"subdivision_code\": \"CA\",
         \"subdivision_name\": \"California\",
         \"subdivision_local_variant\": null
       }]
     }'
   ```

2. Verify the state code is now in the database:
   ```sql
   SELECT * FROM iso_3166 
   WHERE country_code = 'US' AND subdivision_code = 'CA';
   ```

3. Clear the cache for affected addresses:
   ```sql
   DELETE FROM address_cache 
   WHERE state_code = 'CA' AND country_code = 'US';
   ```

### Incorrect state mapping

**Symptoms**:
- Wrong state name returned for a state code

**Fix**:

1. Update the ISO 3166 record:
   ```sql
   UPDATE iso_3166
   SET subdivision_name = 'Correct Name'
   WHERE country_code = 'US' AND subdivision_code = 'CA';
   ```

2. Clear affected cache entries:
   ```sql
   DELETE FROM address_cache 
   WHERE state_code = 'CA' AND country_code = 'US';
   ```

## ECS deployment issues

### Task fails to start

**Symptoms**:
- Deployment fails
- ECS tasks in \"STOPPED\" state
- CloudWatch logs show startup errors

**Common causes**:

1. **Missing environment variables**:
   - Check task definition environment variables
   - Verify Secrets Manager secrets are accessible

2. **Port conflict**:
   - Ensure container port matches ALB target group port
   - Check security group rules

3. **Health check failures**:
   - Verify `/healthz` endpoint is accessible
   - Check database connectivity

**Fix**:

1. Check task stopped reason:
   ```bash
   aws ecs describe-tasks \
     --cluster staging-ecs-cluster \
     --tasks TASK_ARN \
     --region ap-south-1
   ```

2. Review CloudWatch logs for the failed task
3. Fix the issue and redeploy

### Service fails to stabilize

**Symptoms**:
- Deployment times out
- New tasks keep failing health checks
- Old tasks continue running

**Fix**:

1. Check ALB target group health:
   ```bash
   aws elbv2 describe-target-health \
     --target-group-arn TARGET_GROUP_ARN \
     --region ap-south-1
   ```

2. Common issues:
   - Health check path incorrect
   - Security group not allowing ALB traffic
   - Application not listening on correct port

3. Rollback if needed (see [Deployment](/engine/address-api/operations/deployment#rollback))

## Monitoring and alerts

### Better Stack not receiving data

**Symptoms**:
- No uptime data in Better Stack
- Missing alerts

**Fix**:

1. Verify Better Stack heartbeat URL is configured
2. Check if `/healthz` endpoint is accessible externally
3. Verify Better Stack API key is valid

### False positive alerts

**Symptoms**:
- Alerts triggered but service is working

**Fix**:

1. Adjust alert thresholds in Better Stack
2. Increase alert delay (e.g., alert after 3 failures instead of 1)
3. Review health check configuration

## Next steps

- [Debugging guide](/engine/address-api/operations/debugging)
- [Database connection](/engine/address-api/operations/database-connection)
- [Deployment](/engine/address-api/operations/deployment)
